{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2efdbf-7806-460a-8d0e-0d80e7fdd1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from 'best_model.pkl'.\n",
      "\n",
      "Input Data:\n",
      "   Machine  DebugSize  MajorImageVersion  ExportSize  IatVRA  \\\n",
      "0      332          0                  7          70    4096   \n",
      "\n",
      "   NumberOfSections  SizeOfStackReserve  DllCharacteristics  ResourceSize  \\\n",
      "0                 4                  12             1048576       1302926   \n",
      "\n",
      "   BitcoinAddresses  \n",
      "0                 0  \n",
      "\n",
      "Prediction:\n",
      "Predicted Class: Malicious\n",
      "Confidence: 68.66%\n",
      "\n",
      "GPT-4o-mini Analysis:\n",
      "Based on the model's prediction of a \"Malicious\" class with a confidence of 68.66%, there are several steps you can take to further analyze the situation and respond effectively. Here are some creative suggestions:\n",
      "\n",
      "### 1. **Deep Dive Analysis**\n",
      "   - **Feature Importance**: Investigate which features contributed most to the model's decision. Understanding these features can help in refining the model and understanding the behavior of potentially malicious activities.\n",
      "   - **Misclassified Cases**: Review similar cases that were classified differently to understand potential boundaries or anomalies in the decision-making process.\n",
      "\n",
      "### 2. **Threshold Adjustment**\n",
      "   - **Confidence Threshold**: Consider adjusting the confidence threshold for classifying an instance as malicious. You could implement a system where lower-confidence predictions are flagged for further review by analysts.\n",
      "\n",
      "### 3. **Collaborate with Experts**\n",
      "   - **Human Review**: Engage cybersecurity experts to review the case identified as malicious. Their insights can provide a practical context that the model may overlook.\n",
      "   - **Crowdsourcing**: If applicable, involve a wider community (like an internal team or external cybersecurity forum) to evaluate the situation.\n",
      "\n",
      "### 4. **Automated Response Mechanism**\n",
      "   - **Alerting System**: Set up an automated alert system for cases classified as malicious above a certain confidence level (e.g., 70%). Automated responses might include isolating the affected systems or initiating a scan for additional threats.\n",
      "\n",
      "### 5. **Scenario Simulation**\n",
      "   - **Threat Hunting**: Develop simulation scenarios based on the prediction. This provides an opportunity to test\n",
      "\n",
      "   different responses and understand potential vulnerabilities.\n",
      "   - **Attack Simulation**: Consider engaging in red team/blue team exercises, simulating a malicious actor's approach to assess the robustness of your defenses.\n",
      "\n",
      "### 6. **Monitoring and Logging**\n",
      "   - **Increase Monitoring**: Temporarily increase logging and monitoring on the affected systems or areas, looking for unusual patterns or activities that align with malicious behavior.\n",
      "   - **Behavioral Analytics**: Use user behavior analytics (UBA) to find deviations from normal patterns of use that could support the model's classification.\n",
      "\n",
      "### 7. **Continuous Learning**\n",
      "   - **Model Retraining**: If the classification is verified, consider using this case in your model's retraining process to improve its accuracy and reduce false positives or negatives in future predictions.\n",
      "   - **Feedback Loop**: Establish feedback mechanisms to inform the model about true positives and negatives, enhancing its learning with real-world data.\n",
      "\n",
      "### 8. **Documentation and Tracing**\n",
      "   - **Incident Report Creation**: Document the findings and actions taken in this case for future reference and as part of a knowledge-sharing process.\n",
      "   - **Traceability**: Implement a system for tracing back any malicious activity identified, creating a historical record to aid in future analyses.\n",
      "\n",
      "### 9. **User Education and Awareness**\n",
      "   - **Internal Training**: Educate employees about potential malicious activities and how to spot them. This proactive approach can help in early detection of threats.\n",
      "   - **Phishing Simulations**: If applicable, conduct phishing simulations to determine the level of employeesâ€™ awareness and readiness against malicious attacks.\n",
      "\n",
      "### 10. **Legal and Regulatory Compliance**\n",
      "   - **Consult Legal Advisors**: Depending on the context, consult with legal teams to ensure compliance with relevant laws and regulations, especially if personal data is involved.\n",
      "   - **Incident Response Plan Review**: Review and update your incident response plan based on lessons learned from this prediction, ensuring your organization is prepared for future threats.\n",
      "\n",
      "### Conclusion\n",
      "While a 68.66% confidence in a malicious prediction merits attention, it is important to combine automated insights with human expertise and proactive measures. Continuous learning and adaptive strategies will further enhance your system's ability to handle potential threats effectively.\n",
      "\n",
      "Chatbot: Let's discuss ransomware attacks and solutions. How can I assist you today?\n"
     ]
    },
    {
     "ename": "ModelNotFoundError",
     "evalue": "Model XGboost-algm not found in any provider.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModelNotFoundError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     90\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChatbot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchatbot_response.choices[\u001b[32m0\u001b[39m].message.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Start the chatbot\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43mchatbot_ransomware\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mchatbot_ransomware\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     80\u001b[39m chatbot_input = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mChatbot: Please provide information and solutions related to ransomware attacks based on the user\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms query u should be only talk about ransomware .\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Send the input to the GPT-4o-mini model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m chatbot_response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mXGboost-algm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchatbot_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweb_search\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     87\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Print the response from the GPT-4o-mini model\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChatbot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchatbot_response.choices[\u001b[32m0\u001b[39m].message.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\g4f\\client\\__init__.py:333\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, provider, stream, proxy, image, image_name, response_format, max_tokens, stop, api_key, ignore_working, ignore_stream, **kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\g4f\\client\\__init__.py:145\u001b[39m, in \u001b[36miter_append_model_and_provider\u001b[39m\u001b[34m(response, last_model, last_provider)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m response\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlast_provider\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\g4f\\client\\__init__.py:68\u001b[39m, in \u001b[36miter_response\u001b[39m\u001b[34m(response, stream, response_format, max_tokens, stop)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response, \u001b[33m'\u001b[39m\u001b[33m__aiter__\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     66\u001b[39m     response = to_sync_generator(response)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFinishReason\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinish_reason\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\g4f\\tools\\run_tools.py:328\u001b[39m, in \u001b[36miter_run_tools\u001b[39m\u001b[34m(iter_callback, model, messages, provider, tool_calls, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m thinking_start_time = \u001b[32m0\u001b[39m\n\u001b[32m    326\u001b[39m processor = ThinkingProcessor()\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFinishReason\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\g4f\\providers\\asyncio.py:46\u001b[39m, in \u001b[36mto_sync_generator\u001b[39m\u001b[34m(generator, stream)\u001b[39m\n\u001b[32m     44\u001b[39m loop = get_running_loop(check_nested=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_generator_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     48\u001b[39m new_loop = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\g4f\\providers\\asyncio.py:41\u001b[39m, in \u001b[36masync_generator_to_list\u001b[39m\u001b[34m(generator)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_generator_to_list\u001b[39m(generator: AsyncIterator) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [item \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m generator]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\g4f\\providers\\any_provider.py:153\u001b[39m, in \u001b[36mAnyProvider.create_async_generator\u001b[39m\u001b[34m(cls, model, messages, stream, media, ignored, conversation, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m providers = [provider \u001b[38;5;28;01mfor\u001b[39;00m provider \u001b[38;5;129;01min\u001b[39;00m providers \u001b[38;5;28;01mif\u001b[39;00m provider.working \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(provider, \u001b[33m\"\u001b[39m\u001b[33mparent\u001b[39m\u001b[33m\"\u001b[39m, provider.\u001b[34m__name__\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignored]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(providers) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ModelNotFoundError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in any provider.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(providers) == \u001b[32m1\u001b[39m:\n\u001b[32m    155\u001b[39m     provider = providers[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mModelNotFoundError\u001b[39m: Model XGboost-algm not found in any provider."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from g4f.client import Client\n",
    "\n",
    "# Load the best saved model\n",
    "model = joblib.load('best_model.pkl')\n",
    "print(\"Loaded best model from 'best_model.pkl'.\")\n",
    "\n",
    "# Define the 10 feature names used in the model\n",
    "features = ['Machine', 'DebugSize', 'MajorImageVersion', 'ExportSize',\n",
    "            'IatVRA', 'NumberOfSections', 'SizeOfStackReserve',\n",
    "            'DllCharacteristics', 'ResourceSize', 'BitcoinAddresses']\n",
    "\n",
    "# Provide a sample input as a dictionary (update these values as needed)\n",
    "sample_data = {\n",
    "    'Machine': 332,\n",
    "    'DebugSize': 0,\n",
    "    'MajorImageVersion': 7,\n",
    "    'ExportSize': 70,\n",
    "    'IatVRA': 4096,\n",
    "    'NumberOfSections': 4,\n",
    "    'SizeOfStackReserve': 12,\n",
    "    'DllCharacteristics': 1048576,\n",
    "    'ResourceSize': 1302926,\n",
    "    'BitcoinAddresses': 0\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the single sample\n",
    "sample_df = pd.DataFrame([sample_data])\n",
    "print(\"\\nInput Data:\")\n",
    "print(sample_df)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(sample_df)[0]\n",
    "\n",
    "# If your model supports probability predictions, get the probabilities\n",
    "try:\n",
    "    probabilities = model.predict_proba(sample_df)[0]\n",
    "    confidence = max(probabilities)\n",
    "except AttributeError:\n",
    "    probabilities = None\n",
    "    confidence = None\n",
    "\n",
    "# Map the prediction (assuming 1 = Benign, 0 = Malicious)\n",
    "label_mapping = {1: \"Benign\", 0: \"Malicious\"}\n",
    "predicted_label = label_mapping.get(prediction, \"Unknown\")\n",
    "\n",
    "print(\"\\nPrediction:\")\n",
    "print(f\"Predicted Class: {predicted_label}\")\n",
    "if confidence is not None:\n",
    "    print(f\"Confidence: {confidence * 100:.2f}%\")\n",
    "\n",
    "# Initialize the GPT-4o-mini client\n",
    "client = Client()\n",
    "\n",
    "# Prepare the input for the GPT-4o-mini model\n",
    "input_text = f\"The model predicted the class as {predicted_label} with a confidence of {confidence * 100:.2f}% if available. Please provide creative suggestions or further analysis based on this prediction.\"\n",
    "\n",
    "# Send the input to the GPT-4o-mini model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": input_text}],\n",
    "    web_search=False\n",
    ")\n",
    "\n",
    "# Print the response from the GPT-4o-mini model\n",
    "print(\"\\nGPT-4o-mini Analysis:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Implement the chatbot for conversing about ransomware attacks\n",
    "def chatbot_ransomware():\n",
    "    print(\"\\nChatbot: Let's discuss ransomware attacks and solutions. How can I assist you today?\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Chatbot: Goodbye! Stay safe from ransomware attacks.\")\n",
    "            break\n",
    "\n",
    "        # Prepare the input for the GPT-4o-mini model with a focus on ransomware\n",
    "        chatbot_input = f\"User: {user_input}\\nChatbot: Please provide information and solutions related to ransomware attacks based on the user's query u should be only talk about ransomware .\"\n",
    "\n",
    "        # Send the input to the GPT-4o-mini model\n",
    "        chatbot_response = client.chat.completions.create(\n",
    "            model=\"XGboost-algm\",\n",
    "            messages=[{\"role\": \"user\", \"content\": chatbot_input}],\n",
    "            web_search=False\n",
    "        )\n",
    "\n",
    "        # Print the response from the GPT-4o-mini model\n",
    "        print(f\"Chatbot: {chatbot_response.choices[0].message.content}\")\n",
    "\n",
    "# Start the chatbot\n",
    "chatbot_ransomware()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66df05-e534-4fbd-b142-4547185d5c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1db6f-2853-4efb-8fa9-325f0b2fffcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
